#!/usr/bin/env python3
"""
Daily Data Scraper
LinkedIn ve Medium'dan gÃ¼nlÃ¼k veri Ã§ekme script'i
Her gÃ¼n saat 08:00'de Ã§alÄ±ÅŸacak ÅŸekilde ayarlanabilir
"""

import os
import sys
import json
import subprocess
from datetime import datetime
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

class DailyScraper:
    def __init__(self):
        self.linkedin_email = os.getenv("LINKEDIN_EMAIL")
        self.linkedin_password = os.getenv("LINKEDIN_PASSWORD")
        self.notification_email = os.getenv("NOTIFICATION_EMAIL", "kizilbaha26@gmail.com")
        self.script_dir = os.path.dirname(os.path.abspath(__file__))
        
    def log(self, message):
        """Log mesajÄ±nÄ± timestamp ile yazdÄ±r"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        print(f"[{timestamp}] {message}")

    def run_linkedin_scraper(self):
        """LinkedIn scraper'Ä± Ã§alÄ±ÅŸtÄ±r"""
        self.log("ğŸ”µ LinkedIn scraper baÅŸlatÄ±lÄ±yor...")
        
        if not self.linkedin_email or not self.linkedin_password:
            self.log("âŒ LinkedIn credentials eksik (LINKEDIN_EMAIL, LINKEDIN_PASSWORD)")
            return False
        
        try:
            # LinkedIn scraper'Ä± Ã§alÄ±ÅŸtÄ±r
            cmd = [
                sys.executable, 
                os.path.join(self.script_dir, "linkedin-scraper.py")
            ]
            
            env = os.environ.copy()
            env.update({
                "LINKEDIN_EMAIL": self.linkedin_email,
                "LINKEDIN_PASSWORD": self.linkedin_password
            })
            
            result = subprocess.run(
                cmd, 
                capture_output=True, 
                text=True, 
                env=env,
                timeout=300  # 5 dakika timeout
            )
            
            if result.returncode == 0:
                self.log("âœ… LinkedIn scraper baÅŸarÄ±yla tamamlandÄ±")
                self.log(f"LinkedIn output: {result.stdout[-200:]}")  # Son 200 karakter
                return True
            else:
                self.log(f"âŒ LinkedIn scraper hatasÄ±: {result.stderr}")
                return False
                
        except subprocess.TimeoutExpired:
            self.log("â° LinkedIn scraper timeout (5 dakika)")
            return False
        except Exception as e:
            self.log(f"âŒ LinkedIn scraper exception: {e}")
            return False

    def run_medium_scraper(self):
        """Medium scraper'Ä± Ã§alÄ±ÅŸtÄ±r"""
        self.log("ğŸŸ  Medium scraper baÅŸlatÄ±lÄ±yor...")
        
        try:
            # Medium scraper'Ä± Ã§alÄ±ÅŸtÄ±r
            cmd = [sys.executable, os.path.join(self.script_dir, "medium-scraper.py")]
            
            result = subprocess.run(
                cmd, 
                capture_output=True, 
                text=True,
                timeout=300  # 5 dakika timeout
            )
            
            if result.returncode == 0:
                self.log("âœ… Medium scraper baÅŸarÄ±yla tamamlandÄ±")
                self.log(f"Medium output: {result.stdout[-200:]}")  # Son 200 karakter
                return True
            else:
                self.log(f"âŒ Medium scraper hatasÄ±: {result.stderr}")
                return False
                
        except subprocess.TimeoutExpired:
            self.log("â° Medium scraper timeout (5 dakika)")
            return False
        except Exception as e:
            self.log(f"âŒ Medium scraper exception: {e}")
            return False

    def check_data_freshness(self):
        """Ã‡ekilen verilerin gÃ¼ncellik durumunu kontrol et"""
        data_dir = os.path.join(self.script_dir, "..", "data")
        
        linkedin_file = os.path.join(data_dir, "linkedin-posts.json")
        medium_file = os.path.join(data_dir, "medium-articles.json")
        
        results = {
            "linkedin": {"exists": False, "fresh": False, "posts": 0, "engagement": {}},
            "medium": {"exists": False, "fresh": False, "articles": 0, "engagement": {}}
        }
        
        # LinkedIn verisini kontrol et
        if os.path.exists(linkedin_file):
            try:
                with open(linkedin_file, 'r', encoding='utf-8') as f:
                    linkedin_data = json.load(f)
                
                results["linkedin"]["exists"] = True
                results["linkedin"]["posts"] = len(linkedin_data.get("posts", []))
                
                # Engagement toplamlarÄ±
                total_likes = sum(post.get("engagement", {}).get("likes", 0) for post in linkedin_data.get("posts", []))
                total_comments = sum(post.get("engagement", {}).get("comments", 0) for post in linkedin_data.get("posts", []))
                total_shares = sum(post.get("engagement", {}).get("shares", 0) for post in linkedin_data.get("posts", []))
                
                results["linkedin"]["engagement"] = {
                    "likes": total_likes,
                    "comments": total_comments,
                    "shares": total_shares
                }
                
                # GÃ¼ncellik kontrolÃ¼ (son 24 saat iÃ§inde mi?)
                last_updated = linkedin_data.get("lastUpdated")
                if last_updated:
                    from dateutil import parser
                    updated_time = parser.parse(last_updated)
                    now = datetime.now(updated_time.tzinfo) if updated_time.tzinfo else datetime.now()
                    results["linkedin"]["fresh"] = (now - updated_time).total_seconds() < 86400  # 24 saat
                
            except Exception as e:
                self.log(f"âš ï¸ LinkedIn veri kontrolÃ¼ hatasÄ±: {e}")
        
        # Medium verisini kontrol et
        if os.path.exists(medium_file):
            try:
                with open(medium_file, 'r', encoding='utf-8') as f:
                    medium_data = json.load(f)
                
                results["medium"]["exists"] = True
                results["medium"]["articles"] = len(medium_data.get("articles", []))
                
                # Engagement toplamlarÄ±
                total_claps = sum(article.get("engagement", {}).get("claps", 0) for article in medium_data.get("articles", []))
                total_responses = sum(article.get("engagement", {}).get("responses", 0) for article in medium_data.get("articles", []))
                total_views = sum(article.get("engagement", {}).get("views", 0) for article in medium_data.get("articles", []))
                
                results["medium"]["engagement"] = {
                    "claps": total_claps,
                    "responses": total_responses,
                    "views": total_views
                }
                
                # GÃ¼ncellik kontrolÃ¼
                last_updated = medium_data.get("lastUpdated")
                if last_updated:
                    from dateutil import parser
                    updated_time = parser.parse(last_updated)
                    now = datetime.now(updated_time.tzinfo) if updated_time.tzinfo else datetime.now()
                    results["medium"]["fresh"] = (now - updated_time).total_seconds() < 86400  # 24 saat
                
            except Exception as e:
                self.log(f"âš ï¸ Medium veri kontrolÃ¼ hatasÄ±: {e}")
        
        return results

    def send_notification(self, success_count, total_count, data_stats):
        """E-mail bildirimi gÃ¶nder (opsiyonel)"""
        try:
            # Basit log mesajÄ± (e-mail gÃ¶nderimi opsiyonel)
            if success_count == total_count:
                self.log(f"ğŸ“§ Bildirim: {success_count}/{total_count} scraper baÅŸarÄ±lÄ±")
            else:
                self.log(f"âš ï¸ Bildirim: {success_count}/{total_count} scraper baÅŸarÄ±lÄ±")
            
            # Data istatistikleri
            linkedin_stats = data_stats.get("linkedin", {})
            medium_stats = data_stats.get("medium", {})
            
            self.log(f"ğŸ“Š LinkedIn: {linkedin_stats.get('posts', 0)} posts, {linkedin_stats.get('engagement', {}).get('likes', 0)} likes")
            self.log(f"ğŸ“Š Medium: {medium_stats.get('articles', 0)} articles, {medium_stats.get('engagement', {}).get('claps', 0)} claps")
            
        except Exception as e:
            self.log(f"ğŸ“§ Bildirim gÃ¶nderme hatasÄ±: {e}")

    def run(self):
        """Ana scraping iÅŸlemini Ã§alÄ±ÅŸtÄ±r"""
        self.log("ğŸš€ Daily Scraper baÅŸlatÄ±lÄ±yor...")
        self.log(f"ğŸ“… Tarih: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        success_count = 0
        total_count = 2
        
        # LinkedIn scraper'Ä± Ã§alÄ±ÅŸtÄ±r
        if self.run_linkedin_scraper():
            success_count += 1
        
        # Medium scraper'Ä± Ã§alÄ±ÅŸtÄ±r
        if self.run_medium_scraper():
            success_count += 1
        
        # Veri durumunu kontrol et
        data_stats = self.check_data_freshness()
        
        # Bildirim gÃ¶nder
        self.send_notification(success_count, total_count, data_stats)
        
        # Ã–zet rapor
        self.log("=" * 50)
        self.log("ğŸ“‹ GÃœNLÃœK SCRAPER RAPORU")
        self.log("=" * 50)
        self.log(f"âœ… BaÅŸarÄ±lÄ±: {success_count}/{total_count}")
        
        linkedin_stats = data_stats.get("linkedin", {})
        medium_stats = data_stats.get("medium", {})
        
        self.log(f"ğŸ”µ LinkedIn: {linkedin_stats.get('posts', 0)} posts")
        if linkedin_stats.get("engagement"):
            eng = linkedin_stats["engagement"]
            self.log(f"   ğŸ“Š {eng.get('likes', 0)} likes, {eng.get('comments', 0)} comments, {eng.get('shares', 0)} shares")
        
        self.log(f"ğŸŸ  Medium: {medium_stats.get('articles', 0)} articles")
        if medium_stats.get("engagement"):
            eng = medium_stats["engagement"]
            self.log(f"   ğŸ“Š {eng.get('claps', 0)} claps, {eng.get('responses', 0)} responses, {eng.get('views', 0)} views")
        
        self.log("=" * 50)
        
        # Exit code
        if success_count == total_count:
            self.log("ğŸ‰ TÃ¼m scraper'lar baÅŸarÄ±yla tamamlandÄ±!")
            return True
        else:
            self.log("âš ï¸ BazÄ± scraper'lar baÅŸarÄ±sÄ±z oldu")
            return False

if __name__ == "__main__":
    scraper = DailyScraper()
    success = scraper.run()
    sys.exit(0 if success else 1) 